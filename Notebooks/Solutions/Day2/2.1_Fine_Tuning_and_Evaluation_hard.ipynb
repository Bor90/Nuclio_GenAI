{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56dc4a0",
   "metadata": {},
   "source": [
    "# Semantic Search: Baseline vs Fine-Tuning Comparison (Hard Corpus)\n",
    "\n",
    "**Goal:** Compare semantic search quality before and after fine-tuning using three approaches, but with a more challenging corpus and queries:\n",
    "\n",
    "1. **Baseline**: Embedding search with FAISS (no fine-tuning)\n",
    "2. **Contrastive Fine-Tuning**: Improve embeddings directly using contrastive learning\n",
    "3. **LoRA Reranking**: Train a lightweight LoRA adapter on a small LLM to rerank FAISS results\n",
    "\n",
    "We'll evaluate each approach using standard information retrieval metrics:\n",
    "- **Hit@K**: Did we find at least one relevant document in the top K results?\n",
    "- **MRR (Mean Reciprocal Rank)**: How high is the first relevant result ranked?\n",
    "- **nDCG (Normalized Discounted Cumulative Gain)**: How well are relevant documents ranked overall?\n",
    "\n",
    "Additionally, we'll test how each approach affects **downstream LLM performance** by using retrieved documents as context for question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884bf757",
   "metadata": {},
   "source": [
    "## Theoretical Background\n",
    "\n",
    "### What is Semantic Search?\n",
    "\n",
    "Traditional keyword search matches exact words, but **semantic search** understands the *meaning* behind queries and documents. For example:\n",
    "- Query: \"Who discovered the first antibiotic?\"\n",
    "- Relevant document: \"Alexander Fleming found penicillin in 1928\"\n",
    "\n",
    "Notice that the words \"discovered,\" \"first,\" and \"antibiotic\" don't appear exactly in the document, but the meaning matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51baf45",
   "metadata": {},
   "source": [
    "### How Does Semantic Search Work?\n",
    "\n",
    "**Step 1: Embedding**\n",
    "- Convert text into dense vectors (arrays of numbers) that capture semantic meaning\n",
    "- Similar meanings â†’ similar vectors (close in vector space)\n",
    "- Example: \"dog\" and \"puppy\" have similar embeddings, but \"dog\" and \"car\" don't\n",
    "\n",
    "**Step 2: Indexing**\n",
    "- Store all document embeddings in a searchable index (we use FAISS)\n",
    "- FAISS enables fast similarity search over millions of vectors\n",
    "\n",
    "**Step 3: Retrieval**\n",
    "- Embed the query using the same model\n",
    "- Find documents with embeddings most similar to the query embedding\n",
    "- Similarity is typically measured using cosine similarity or dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac7834",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "We'll use Python libraries for data handling, modeling, and evaluation. For the interactive app, we'll use Gradio (or Streamlit as an alternative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281336b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install -q gradio faiss-cpu scikit-learn pandas numpy tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import gradio as gr\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefeaf17",
   "metadata": {},
   "source": [
    "## Prepare a Harder Text Corpus\n",
    "\n",
    "We'll use a more challenging, longer, and ambiguous synthetic corpus to make retrieval and classification harder. You can also swap this for a real dataset (e.g., 20 Newsgroups) if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa897c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a harder, longer, and more ambiguous synthetic corpus\n",
    "corpus = [\n",
    "    \"The quick brown fox jumps over the lazy dog near the river bank, while the sun sets behind the mountains.\",\n",
    "    \"A bank can be a financial institution or the side of a river, depending on the context of the sentence.\",\n",
    "    \"The astronomer observed the stars through the telescope, but the bank's interest rates were also rising.\",\n",
    "    \"The chef prepared a delicious meal with rare spices, while the banker discussed loans with a client.\",\n",
    "    \"A bat can refer to a flying mammal or a piece of sports equipment used in cricket or baseball.\",\n",
    "    \"The cricket match was interrupted by a sudden downpour, and the players took shelter in the pavilion.\",\n",
    "    \"The lawyer presented the case in court, but the judge was more interested in the evidence.\",\n",
    "    \"The artist painted a beautiful landscape, capturing the essence of the countryside in spring.\",\n",
    "    \"The computer crashed during the presentation, causing the speaker to lose all unsaved work.\",\n",
    "    \"The patient was prescribed a new medication, but the pharmacist warned about possible side effects.\",\n",
    "    # Add more ambiguous and context-rich sentences\n",
    "    \"The coach gave a pep talk before the game, but the team was still nervous about the final.\",\n",
    "    \"The engineer designed a bridge that could withstand earthquakes and heavy traffic.\",\n",
    "    \"The gardener planted roses and tulips, hoping for a colorful bloom in the summer.\",\n",
    "    \"The pilot announced a delay due to bad weather, and the passengers groaned in frustration.\",\n",
    "    \"The musician composed a symphony inspired by the sounds of the city at night.\",\n",
    "    \"The teacher explained the concept of gravity using simple experiments in the classroom.\",\n",
    "    \"The detective solved the mystery by finding a crucial clue at the crime scene.\",\n",
    "    \"The doctor recommended regular exercise and a balanced diet for better health.\",\n",
    "    \"The programmer debugged the code, fixing a bug that caused the app to crash.\",\n",
    "    \"The historian wrote a book about ancient civilizations and their cultural impact.\"\n",
    "]\n",
    "\n",
    "# Create challenging queries that require deeper understanding\n",
    "queries = [\n",
    "    \"What is the meaning of the word 'bank' in different contexts?\",\n",
    "    \"Describe a scenario where a bat is not an animal.\",\n",
    "    \"How can a computer failure affect a public event?\",\n",
    "    \"What are the possible side effects of new drugs?\",\n",
    "    \"Explain how a bridge can be made earthquake-resistant.\",\n",
    "    \"How does gravity influence classroom experiments?\",\n",
    "    \"What is the role of a judge in a legal case?\",\n",
    "    \"How do musicians find inspiration for their work?\",\n",
    "    \"What are the responsibilities of a pharmacist?\",\n",
    "    \"How do weather conditions impact air travel?\"\n",
    "]\n",
    "\n",
    "# Create ground truth for evaluation (index of relevant corpus sentence for each query)\n",
    "relevant_indices = [1, 4, 8, 9, 11, 15, 6, 14, 9, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3934deb",
   "metadata": {},
   "source": [
    "## Explore and Preprocess the Corpus\n",
    "\n",
    "Let's inspect the corpus and queries, then preprocess the text (lowercasing, removing punctuation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5412da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the corpus and queries\n",
    "print(\"Sample corpus sentences:\")\n",
    "for i, sent in enumerate(corpus[:5]):\n",
    "    print(f\"{i}: {sent}\")\n",
    "\n",
    "print(\"\\nSample queries:\")\n",
    "for i, q in enumerate(queries[:5]):\n",
    "    print(f\"{i}: {q}\")\n",
    "\n",
    "# Simple text preprocessing\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "corpus_clean = [preprocess(s) for s in corpus]\n",
    "queries_clean = [preprocess(q) for q in queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17d28a",
   "metadata": {},
   "source": [
    "## Build and Train a Text Classification Model\n",
    "\n",
    "We'll vectorize the text using TF-IDF and train a logistic regression classifier to predict which corpus sentence is relevant to a given query. This is a simplification for demonstration; in practice, you would use semantic embeddings and more advanced models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13008379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize corpus and queries\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus_vecs = vectorizer.fit_transform(corpus_clean)\n",
    "queries_vecs = vectorizer.transform(queries_clean)\n",
    "\n",
    "# For demonstration, train a classifier to map queries to relevant corpus indices\n",
    "X = queries_vecs\n",
    "y = relevant_indices\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Evaluate on training data (since we have few samples)\n",
    "preds = clf.predict(X)\n",
    "print(\"Classification report (query to relevant corpus sentence):\")\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f7a28",
   "metadata": {},
   "source": [
    "## Create an Interactive App to Load Custom Datasets\n",
    "\n",
    "We'll build a Gradio app that allows you to upload your own CSV/text dataset, preprocess it, and apply the trained model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio app for custom dataset upload and prediction\n",
    "def predict_custom(queries, custom_corpus):\n",
    "    # Preprocess\n",
    "    custom_corpus_clean = [preprocess(s) for s in custom_corpus]\n",
    "    queries_clean = [preprocess(q) for q in queries]\n",
    "    # Vectorize\n",
    "    custom_corpus_vecs = vectorizer.transform(custom_corpus_clean)\n",
    "    queries_vecs = vectorizer.transform(queries_clean)\n",
    "    # Predict relevant corpus index for each query\n",
    "    preds = clf.predict(queries_vecs)\n",
    "    # Return the predicted relevant sentence for each query\n",
    "    results = [custom_corpus[p] if 0 <= p < len(custom_corpus) else \"No match\" for p in preds]\n",
    "    return results\n",
    "\n",
    "def gradio_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Custom Semantic Search Demo\\nUpload your own corpus and enter queries to see predictions.\")\n",
    "        corpus_input = gr.Textbox(label=\"Custom Corpus (one sentence per line)\", lines=10)\n",
    "        queries_input = gr.Textbox(label=\"Queries (one per line)\", lines=5)\n",
    "        output = gr.Textbox(label=\"Predicted Relevant Sentences\", lines=10)\n",
    "        def run_app(corpus_text, queries_text):\n",
    "            custom_corpus = [s.strip() for s in corpus_text.split(\"\\n\") if s.strip()]\n",
    "            queries = [q.strip() for q in queries_text.split(\"\\n\") if q.strip()]\n",
    "            results = predict_custom(queries, custom_corpus)\n",
    "            return \"\\n\".join(results)\n",
    "        btn = gr.Button(\"Predict\")\n",
    "        btn.click(run_app, inputs=[corpus_input, queries_input], outputs=output)\n",
    "    return demo\n",
    "\n",
    "demo = gradio_interface()\n",
    "# Uncomment the next line to launch the app in a notebook or script\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434a081",
   "metadata": {},
   "source": [
    "## Test the App with a Custom Dataset\n",
    "\n",
    "Let's demonstrate the app by loading a sample custom corpus and queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test the app with a sample custom corpus and queries\n",
    "sample_corpus = [\n",
    "    \"The volcano erupted, sending ash into the sky.\",\n",
    "    \"A chef uses a knife to chop vegetables.\",\n",
    "    \"The scientist published a paper on climate change.\",\n",
    "    \"The athlete won a gold medal at the Olympics.\"\n",
    "]\n",
    "sample_queries = [\n",
    "    \"Who studies the environment?\",\n",
    "    \"What tool does a chef use?\",\n",
    "    \"Describe a natural disaster involving ash.\"\n",
    "]\n",
    "\n",
    "results = predict_custom(sample_queries, sample_corpus)\n",
    "for q, r in zip(sample_queries, results):\n",
    "    print(f\"Query: {q}\\nPredicted relevant: {r}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
